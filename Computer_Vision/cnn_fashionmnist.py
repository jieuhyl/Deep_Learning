# -*- coding: utf-8 -*-
"""CNN_FashionMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BC3ITtQEsmyLWAO1WgyNYZPJR8rH9069
"""

import tensorflow as tf
print(tf.__version__)

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# additional imports
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Conv2D, Dense, Activation, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization, LeakyReLU
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import regularizers, optimizers
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

# Load in the data
fashion_mnist = tf.keras.datasets.fashion_mnist

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

x_train = x_train.astype('float32')/255
x_test = x_test.astype('float32')/255
print("x_train.shape:", x_train.shape)
print("y_train.shape", y_train.shape)

import matplotlib.pyplot as plt
import seaborn as sns

# shoe
#scaled_single = x_train[0]
#scaled_single.max()
plt.imshow(x_train[0])

# convolution expects height x width x color
#x_train = np.expand_dims(x_train, -1)
#x_test = np.expand_dims(x_test, -1)

x_train = x_train.reshape(60000, 28, 28, 1)
x_test = x_test.reshape(10000,28,28,1)
print("x_train.shape:", x_train.shape)
print("y_train.shape", y_train.shape)

# number of classes
K = len(set(y_train))
print("number of classes:", K)

y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

x_train[0].shape

# build model
model = Sequential(name = 'CNN_fashionmnist')
model.add(Conv2D(32, kernel_size=(3,3), padding ="same", input_shape=(28,28,1)))
model.add(LeakyReLU(alpha = 0.01))
model.add(Conv2D(32, kernel_size=(3,3), padding ="same"))
model.add(LeakyReLU(alpha = 0.01))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.3))

model.add(Conv2D(64, kernel_size=(3,3), padding ="same"))
model.add(LeakyReLU(alpha = 0.01))
model.add(Conv2D(64, kernel_size=(3,3), padding ="same"))
model.add(LeakyReLU(alpha = 0.01))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.4))

model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.summary()

# run model
model.compile(optimizer='Adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train_cat, 
          validation_data=(x_test, y_test_cat), 
          batch_size = 128, epochs = 20)

def plotmodelhistory(history): 
    fig, axs = plt.subplots(1,2,figsize=(15,5)) 
    # summarize history for accuracy
    axs[0].plot(history.history['accuracy']) 
    axs[0].plot(history.history['val_accuracy']) 
    axs[0].set_title('Model Accuracy')
    axs[0].set_ylabel('Accuracy') 
    axs[0].set_xlabel('Epoch')
    axs[0].legend(['train', 'validate'], loc='upper left')
    # summarize history for loss
    axs[1].plot(history.history['loss']) 
    axs[1].plot(history.history['val_loss']) 
    axs[1].set_title('Model Loss')
    axs[1].set_ylabel('Loss') 
    axs[1].set_xlabel('Epoch')
    axs[1].legend(['train', 'validate'], loc='upper left')
    plt.show()

plotmodelhistory(model.history)

y_pred = np.argmax(model.predict(x_test),axis =1)
error = 0
confusion_matrix = np.zeros([10,10])
for i in range(x_test.shape[0]):
    confusion_matrix[y_test[i],y_pred[i]] += 1
    if y_test[i]!=y_pred[i]:
        error +=1
        
confusion_matrix,error,(error*100)/y_pred.shape[0],100-(error*100)/y_pred.shape[0],y_pred.shape[0]

print("Confusion Matrix: \n\n" ,confusion_matrix)
print("\nErrors in validation set: " ,error)
print("\nError Persentage : " ,(error*100)/y_pred.shape[0])
print("\nAccuracy : " ,100-(error*100)/y_pred.shape[0])
print("\nValidation set Shape :",y_pred.shape[0])

f = plt.figure(figsize=(12, 9))
f.add_subplot(111)

plt.imshow(np.log2(confusion_matrix+1),cmap="Reds")
plt.colorbar()
plt.tick_params(size=5,color="white")
plt.xticks(np.arange(0,10),np.arange(0,10))
plt.yticks(np.arange(0,10),np.arange(0,10))

threshold = confusion_matrix.max()/2 

for i in range(10):
    for j in range(10):
        plt.text(j,i,int(confusion_matrix[i,j]),horizontalalignment="center",color="white" if confusion_matrix[i, j] > threshold else "black")
        
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.savefig("Confusion_matrix2.png")
plt.show()

predicted_classes = model.predict_classes(x_test)
#predicted_classes = (model.predict(x_test) > 0.5).astype("int32")

p = predicted_classes[:10000]
y = y_test[:10000]
correct = np.nonzero(p==y)[0]
incorrect = np.nonzero(p!=y)[0]

print("Correct predicted classes:",correct.shape[0])
print("Incorrect predicted classes:",incorrect.shape[0])

# Create a dictionary for each type of label 
labels = {0 : "T-shirt/top", 1: "Trouser", 2: "Pullover", 3: "Dress", 4: "Coat",
          5: "Sandal", 6: "Shirt", 7: "Sneaker", 8: "Bag", 9: "Ankle Boot"}

def plot_images(data_index, cmap="Blues"):
    # Plot the sample images now
    f, ax = plt.subplots(4,4, figsize=(15,15))

    for i, idx in enumerate(data_index[:16]):
        ax[i//4, i%4].imshow(x_test[idx].reshape(28, 28), cmap=cmap)
        ax[i//4, i%4].axis('off')
        ax[i//4, i%4].set_title("True:{},  Pred:{}".format(labels[y_test[idx]], labels[predicted_classes[idx]]))
    plt.show()

plot_images(correct, "Greens")

plot_images(incorrect, "Reds")

